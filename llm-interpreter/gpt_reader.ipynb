{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import PyPDF2\n",
    "import os\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import tabula\n",
    "import os\n",
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from openai import OpenAI\n",
    "from unidecode import unidecode\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from unidecode import unidecode\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  organization='a',\n",
    "  api_key = 'a'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leitorProcessual:\n",
    "    def __init__(self):\n",
    "        self.informacoes = fr\"\"\"\n",
    "            processo_numero: \n",
    "            processo_unico:\n",
    "            autor: (Nome de quem abriu o processo);\n",
    "            estrategia: (se é defesa ou ataque)\n",
    "            advogado_monitorado: \n",
    "            data_distribuicao: (data da distribuição do processo)\n",
    "            data_citacao: (data do AR indicado para o réu)\n",
    "            valor_acao: (valor indicado pelo autor)\n",
    "            revelia:\n",
    "            modalidade_pagamento: (interno)\n",
    "            pagamento: (prinicipal ou complementação)\n",
    "            sentenca_dados_decisao: True/False (depende se existe ou não)\n",
    "            data_publicacao_sentenca: (data em que a sentença foi publicada)\n",
    "            sentenca_resultado:(parcial procedência, negado, total procedência)\n",
    "            sentenca_dispositivo: todas informações do dispositivo da sentença.\n",
    "            recurso: True/False\n",
    "            recurso_origem: autor/reu/ambos\n",
    "            dispositivo_recurso: todas informações do dispositivo do recurso. \n",
    "            \"\"\"\n",
    "        \n",
    "    def organizar_arquivos(self, pdf_file):\n",
    "        page_content = {}\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file) \n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            page_content[page_num + 1] = text\n",
    "\n",
    "        def remove_newlines(text_dict):\n",
    "            return {key: value.replace(\"\\n\", \"\") for key, value in text_dict.items()}\n",
    "\n",
    "        updated_dictionary = remove_newlines(page_content)\n",
    "\n",
    "        count_per_page = {page: len(content.split()) for page, content in updated_dictionary.items()}\n",
    "        # count_per_page = {page: len(content.replace(' ', '')) for page, content in updated_dictionary.items()}\n",
    "\n",
    "        counts = list(count_per_page.values())\n",
    "        percentile_50 = np.percentile(counts, 50)\n",
    "        filtered_pages = {page: count for page, count in count_per_page.items() if count > percentile_50}\n",
    "        lista_parse_pagina = list(filtered_pages.keys())\n",
    "\n",
    "        return updated_dictionary, lista_parse_pagina\n",
    "        \n",
    "    def remover_acentos(self, texto):\n",
    "        if pd.isna(texto):\n",
    "            return texto  # Mantém o NaN como está\n",
    "        return unidecode(texto)\n",
    "\n",
    "    def sumarizar_pdf(self, updated_dictionary, lista_parse_pagina):\n",
    "        estrutura_geral = []\n",
    "        for i in tqdm(range(0,len(lista_parse_pagina)), desc='Parsing pages'):\n",
    "            texto_pagina = updated_dictionary[lista_parse_pagina[i]]\n",
    "            response = client.chat.completions.create(\n",
    "                model='gpt-3.5-turbo-0125',\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":\"Você é um interpretador e organizador de dados não estruturados\"},\n",
    "                    {\"role\":\"system\",\"content\": f\"Dado o seguinte texto extraído de um documento na página {i}, identifique e estruture as informações\"},\n",
    "                    {\"role\":\"system\",\"content\": f\"Por favor, SEMPRE retorne as informações no seguinte formato e com separador '|': 'palavra-chave do campo|informação_pretendida\"},\n",
    "                    {\"role\":\"system\",\"content\": f\"Se não retornar encontrar a informação, colocar o texto: sem_informacao.\"},\n",
    "                    {\"role\":\"system\",\"content\": self.informacoes},\n",
    "                    {\"role\":\"user\",\"content\": f\"Segue a página extraída: {texto_pagina}\"}\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "                top_p=1.0,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "            )\n",
    "\n",
    "            resposta = response.choices[0].message.content.strip().split('\\n')\n",
    "            estruturado = []\n",
    "            for line in resposta:\n",
    "                parts = line.split('|')\n",
    "                if len(parts) == 2:\n",
    "                    item = {\n",
    "                        'campo': parts[0],\n",
    "                        'informacao': parts[1] if parts[1] != 'sem_informacao' else np.nan,\n",
    "                        'id': i\n",
    "                    }\n",
    "                    estruturado.append(item)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            estrutura_geral.append(estruturado)\n",
    "\n",
    "        dados_gerais = []\n",
    "        for sublista in estrutura_geral:\n",
    "            for dicionario in sublista:\n",
    "                dados_gerais.append(dicionario)\n",
    "\n",
    "        return dados_gerais\n",
    "    \n",
    "    def ajuste_dados_sumarizacao(self, pdf_file, dados_gerais):\n",
    "\n",
    "        df_geral = pd.DataFrame(dados_gerais)\n",
    "        df_geral.dropna(inplace=True)\n",
    "        df_geral['informacao'] = df_geral['informacao'].apply(self.remover_acentos)\n",
    "        df_geral['informacao'] = df_geral['informacao'].str.replace('R$', '', regex=False)\n",
    "        contagem = df_geral.groupby(['campo', 'informacao']).size().reset_index(name='contagem')\n",
    "        df_geral = df_geral.merge(contagem, on=['campo', 'informacao'], how='left')\n",
    "        df_geral['informacao'] = df_geral['informacao'].str.upper().str.strip()\n",
    "        df_geral.drop_duplicates(subset=['campo', 'informacao'], keep='first', inplace=True)\n",
    "        df_geral.sort_values(by=['campo', 'id'], inplace=True)\n",
    "\n",
    "        df_geral.to_excel(f'arquivo_temporario_{os.path.splitext(pdf_file)[0]}.xlsx', index=False)\n",
    "\n",
    "        return df_geral\n",
    "        \n",
    "\n",
    "    def analise_informacoes(self, pdf_file, df_geral):\n",
    "        parse_final = df_geral.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4-turbo',\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":\"Você é um interpretador e organizador de dados não estruturados\"},\n",
    "                {\"role\":\"system\",\"content\": f\"As informações apresentada advém de um dataframe oriundo leitura de um processo judicial por meio de IA.\"},\n",
    "                {\"role\":\"system\",\"content\": f\"A coluna campo refere-se a informação, a coluna contagem a quantas vezes aquela informação se repete, a coluna id é a primeira página de ocorrência e a coluna informacao tem o content\"},\n",
    "                {\"role\":\"system\",\"content\": f\"Faça uma análise criteriosa olhando a contagem e o conteúdo da coluna 'informacao' para esses dados. Conforme as várias informações, construa uma que corrobore com o conteúdo dado e descarte as que não faz ideia.\"},\n",
    "                {\"role\":\"system\",\"content\": f\"A saída deve conter apenas este formato: campo | informacao | id\"},\n",
    "                {\"role\":\"system\",\"content\": f\"Preciso que evite repetições das informações, quero apenas uma linha para cada campo.\"},\n",
    "                {\"role\":\"user\",\"content\": f\"Segue as informações em formato json: {parse_final}\"}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0\n",
    "        )\n",
    "\n",
    "        resposta = response.choices[0].message.content.strip().split('\\n')\n",
    "\n",
    "        estruturado = []\n",
    "        for line in resposta:\n",
    "            parts = line.split('|')\n",
    "            if len(parts) == 3:\n",
    "                item = {\n",
    "                    'campo': parts[0],\n",
    "                    'informacao': parts[1],\n",
    "                    'id': parts[2]\n",
    "                }\n",
    "                estruturado.append(item)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        df = pd.DataFrame(estruturado)\n",
    "        df.to_excel(f'tabela_final_{os.path.splitext(pdf_file)[0]}.xlsx', index=False)\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumarizador = leitorProcessual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = 'copia_integral_5010463-27.2022.8.24.0930.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dictionary, lista_parse_pagina = sumarizador.organizar_arquivos(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custo antes: 0,90\n",
    "# custo depois: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_gerais = sumarizador.sumarizar_pdf(updated_dictionary, lista_parse_pagina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geral = sumarizador.ajuste_dados_sumarizacao(pdf_file,dados_gerais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_informacoes = sumarizador.analise_informacoes(pdf_file, df_geral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TED e DED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytesseract PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tabula-py[jpype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = 'C:/Program Files (x86)/Java/jdk-11.0.22/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_dfs = tabula.read_pdf('TED - ESTORNO (2).pdf', pages='all', area=[1,1,3000,3000], multiple_tables='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = []\n",
    "\n",
    "for i in range(0,len(tabula_dfs)):\n",
    "    date_pattern = r'\\d{2}/\\d{2}/\\d{4}'\n",
    "    date_match = re.search(date_pattern, tabula_dfs[0]['Transferência Eletrônica Disponível - TED \"IF-CLI\"'].iloc[16])\n",
    "    valor = tabula_dfs[i]['Unnamed: 3'].iloc[11]\n",
    "    hora = tabula_dfs[i]['Unnamed: 0'].iloc[11]\n",
    "\n",
    "    dicionario = {\n",
    "        'data': date_match.group() if date_match else None,\n",
    "        'hora': hora,\n",
    "        'valor': valor,\n",
    "        'pagina': i+1\n",
    "    }\n",
    "\n",
    "    dados.append(dicionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalador do tesseract: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "# baixar por.traineddata https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata (leitura em português)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_dfs = tabula.read_pdf('DED.pdf', pages='all', area=[225,1,3000,3000], multiple_tables='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_concat = pd.concat(tabula_dfs, ignore_index=True)[[\"DT. VCTO.\",\"PARC.\",\"VLR. FINAL\",\"TOT. DIVIDA\",\"VLR.LNC./PG.\",\"HIST. FINANC.\"]].dropna(subset=[\"DT. VCTO.\"])\n",
    "tabela_concat = tabela_concat[tabela_concat[\"DT. VCTO.\"] != \"Continua ...\"]\n",
    "# tabela_concat[tabela_concat['HIST. FINANC.'] == '101 - Baixa Empregador']\n",
    "tabela_concat[['codigo', 'descricao']] = tabela_concat['HIST. FINANC.'].str.split(' - ', expand=True)\n",
    "tabela_concat[['texto', 'valor']] = tabela_concat['VLR.LNC./PG.'].str.extract(r'(.*?)(\\d+,\\d+)$')\n",
    "tabela_concat[tabela_concat['codigo'] == '101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TESSDATA_PREFIX'] = r'C:/Program Files/Tesseract-OCR/tessdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe'  # Caminho para o executável do tesseract\n",
    "\n",
    "parse_pdf = []\n",
    "\n",
    "# Abra o arquivo PDF com o PyMuPDF\n",
    "pdf_file = 'DED.pdf'\n",
    "pdf = fitz.open(pdf_file)\n",
    "\n",
    "# Itere pelas páginas e aplique OCR\n",
    "for page_num in tqdm(range(len(pdf)), desc='Parsing pages'):\n",
    "    # Obtenha a página\n",
    "    page = pdf[page_num]\n",
    "\n",
    "    # Renderize a página em uma imagem\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    # Extraia o texto da imagem usando OCR\n",
    "    content = pytesseract.image_to_string(img, lang='por')  # Especifique o idioma com o parâmetro lang, se necessário\n",
    "\n",
    "    dicionario = {\n",
    "        'page_num': page_num + 1,\n",
    "        'conteudo': content\n",
    "    }\n",
    "\n",
    "    # Faça o que você precisar com o texto\n",
    "    parse_pdf.append(content)\n",
    "\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(parse_pdf)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
