{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Pacotes para o relatório de hardware\n",
    "import gc\n",
    "import types\n",
    "import pkg_resources\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Seed para reproduzir os mesmos resultados\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'imagens_audio/melspectrogram_224/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv')\n",
    "labels['file_name'] = labels['file_name'].apply(lambda x: f\"{x.split('.')[0]}.png\")\n",
    "labels['file_path'] = labels['file_name'].apply(lambda x: os.path.join(image_folder, x))\n",
    "labels['chord_idx'] = pd.Categorical(labels['chord']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para cálculo de média e desvio\n",
    "def calcula_img_mean_std(image_paths):\n",
    "    img_h, img_w = 224, 224\n",
    "    \n",
    "    n_pixels = img_h * img_w\n",
    "    channel_sum = np.zeros(3)\n",
    "    channel_sum_squared = np.zeros(3)\n",
    "    \n",
    "    for path in tqdm(image_paths):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (img_w, img_h))\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        \n",
    "        # Atualiza a soma e a soma dos quadrados\n",
    "        channel_sum += np.sum(img, axis=(0, 1))\n",
    "        channel_sum_squared += np.sum(np.square(img), axis=(0, 1))\n",
    "    \n",
    "    # Calcula a média e o desvio padrão\n",
    "    means = channel_sum / (n_pixels * len(image_paths))\n",
    "    stdevs = np.sqrt(channel_sum_squared / (n_pixels * len(image_paths)) - np.square(means))\n",
    "\n",
    "    # BGR --> RGB\n",
    "    means = means[::-1]\n",
    "    stdevs = stdevs[::-1]\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    \n",
    "    return means, stdevs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_mean, norm_std = calcula_img_mean_std(labels['file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normMean = [0.30298967, 0.11516446, 0.23933927]\n",
    "normStd = [0.35485684, 0.16791199, 0.2177703 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save_images(input_folder, output_folder, new_size=(224, 224)):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder, exist_ok=True) \n",
    "\n",
    "    # Ajuste aqui para verificar os arquivos corretamente\n",
    "    parsed_files = list_files_in_directory(output_folder)\n",
    "    parsed_files_base = [os.path.splitext(f)[0] for f in parsed_files]\n",
    "\n",
    "    image_paths = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg')) and os.path.splitext(f)[0] not in parsed_files_base]\n",
    "\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            img_resized = cv2.resize(img, new_size)\n",
    "            base_name = os.path.basename(path)\n",
    "            save_path = os.path.join(output_folder, base_name)\n",
    "            cv2.imwrite(save_path, img_resized)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_and_save_images('imagens_audio/melspectrogram/','imagens_audio/melspectrogram_224/', new_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels['chord_idx']\n",
    "_, df_validacao = train_test_split(labels, test_size = 0.2, random_state = 101, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao['chord_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função identifica se uma imagem faz parte do conjunto train ou val\n",
    "def get_val_rows(x):\n",
    "    val_list = list(df_validacao['clean'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica treino ou validação\n",
    "labels['train_or_val'] = labels['clean']\n",
    "labels['train_or_val'] = labels['train_or_val'].apply(get_val_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra as linhas de treino\n",
    "df_treino = labels[labels['train_or_val'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_treino))\n",
    "print(len(df_validacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['chord_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao['chord'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df_treino['chord_idx'].value_counts()\n",
    "max_instances = class_counts.max()\n",
    "data_aug_rate = max_instances // class_counts - 1\n",
    "data_aug_rate = data_aug_rate.apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = []\n",
    "\n",
    "for i in range(372):\n",
    "\n",
    "    if data_aug_rate[i] > 0:\n",
    "        class_subset = df_treino[df_treino['chord_idx'] == i]\n",
    "        augmented_subset = pd.DataFrame(np.repeat(class_subset.values, data_aug_rate[i], axis=0))\n",
    "        augmented_subset.columns = class_subset.columns\n",
    "        augmented_data.append(augmented_subset)\n",
    "\n",
    "df_treino = pd.concat([df_treino] + augmented_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['chord_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos dividir o conjunto de validação em um conjunto de validação e um conjunto de teste\n",
    "df_validacao, df_teste = train_test_split(df_validacao, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_validacao = df_validacao.reset_index()\n",
    "df_teste = df_teste.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extracting é um booleano que define se estamos fazendo um ajuste fino ou extração de recursos.\n",
    "# Se feature_extracting = False, o modelo é ajustado e todos os parâmetros do modelo são atualizados.\n",
    "# Se feature_extracting = True, apenas os parâmetros da última camada são atualizados, os outros permanecem fixos.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para inicializar diferentes arquiteturas de Deep Learning\n",
    "def inicializa_modelo(model_name, num_classes, feature_extract, use_pretrained = True):\n",
    "\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    # Usaremos o modelo resnet50\n",
    "    if model_name == \"resnet\":\n",
    "        \n",
    "        # Tamanho (pixels) das imagens de entrada\n",
    "        input_size = 224\n",
    "        \n",
    "        # Carregamos o modelo pré-treinado com todos os pesos\n",
    "        model_ft = models.resnet50(pretrained = use_pretrained)\n",
    "        \n",
    "        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        \n",
    "        # Define o número de atributos de entrada\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        \n",
    "        # Camada linear final para prever a probabilidade das 7 classes com as quais estamos trabalhando\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Usaremos o modelo Densenet121\n",
    "    elif model_name == \"densenet\":\n",
    "        \n",
    "        # Tamanho (pixels) das imagens de entrada\n",
    "        input_size = 224\n",
    "        \n",
    "        # Carregamos o modelo pré-treinado com todos os pesos\n",
    "        model_ft = models.densenet121(pretrained = use_pretrained)\n",
    "        \n",
    "        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        \n",
    "        # Define o número de atributos de entrada\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        \n",
    "        # Camada linear final para prever a probabilidade das 7 classes com as quais estamos trabalhando\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Usaremos o Inception V3\n",
    "    elif model_name == \"inception\":\n",
    "        \n",
    "        # Tamanho (pixels) das imagens de entrada\n",
    "        # Tenha cuidado, pois espera-se (299 x 299) para o tamanho das imagens e ainda tem saída auxiliar\n",
    "        input_size = 299\n",
    "\n",
    "        # Carregamos o modelo pré-treinado com todos os pesos\n",
    "        model_ft = models.inception_v3(pretrained = use_pretrained)\n",
    "        \n",
    "        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        \n",
    "        # Tratando a auxilary net da arquitetura Inceptio\n",
    "        model_ft.aux_logits = False\n",
    "        \n",
    "        # Tratando a primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    else:\n",
    "        print(\"Modelo inválido...\")\n",
    "        exit()\n",
    "        \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina um organizador de dados para modelo PyTorch \n",
    "class OrganizaDados(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = Image.open(self.df['file_path'][index])\n",
    "        y = torch.tensor(int(self.df['chord_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular erro em treino e validação durante o treinamento\n",
    "class CalculaMetricas(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para erro e acurácia em treino\n",
    "total_loss_train, total_acc_train = [],[]\n",
    "# Função de treino do modelo\n",
    "def treina_modelo(treino_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # Coloca o modelo em modo de treino\n",
    "    model.train()\n",
    "    \n",
    "    # Inicializa objetos de cálculo de métricas\n",
    "    train_loss = CalculaMetricas()\n",
    "    train_acc = CalculaMetricas()\n",
    "    \n",
    "    # Iteração\n",
    "    curr_iter = (epoch - 1) * len(treino_loader)\n",
    "    \n",
    "    # Loop de treino\n",
    "    for i, data in enumerate(treino_loader):\n",
    "        \n",
    "        # Extra os dados\n",
    "        images, labels = data\n",
    "        \n",
    "        # Tamanho da imagem\n",
    "        N = images.size(0)\n",
    "        \n",
    "        # Coloca imagens e labels no device\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        # Zera os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Previsão do modelo\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Erro do modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Obtem a previsão de maior probabilidade\n",
    "        prediction = outputs.max(1, keepdim = True)[1]\n",
    "        \n",
    "        # Atualiza as métricas\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        \n",
    "        # Iteração\n",
    "        curr_iter += 1\n",
    "        \n",
    "        # Print e update das métricas\n",
    "        # A condição *** and curr_iter < 1000 *** pode ser removida se você quiser treinar com o dataset completo\n",
    "        if (i + 1) % 100 == 0 and curr_iter < 1000:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (epoch, \n",
    "                                                                                       i + 1, \n",
    "                                                                                       len(treino_loader), \n",
    "                                                                                       train_loss.avg, \n",
    "                                                                                       train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "            \n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_val, total_acc_val = [],[]\n",
    "# Função para validação\n",
    "def valida_modelo(val_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # Coloca o modelo em modo de validação\n",
    "    model.eval()\n",
    "    \n",
    "    # Inicializa objetos de cálculo de métricas\n",
    "    val_loss = CalculaMetricas()\n",
    "    val_acc = CalculaMetricas()\n",
    "    \n",
    "    # Validação\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            \n",
    "            images, labels = data\n",
    "            \n",
    "            N = images.size(0)\n",
    "            \n",
    "            images = Variable(images).to(device)\n",
    "            \n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            \n",
    "            prediction = outputs.max(1, keepdim = True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicializando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo que será treinado\n",
    "#nome_modelo = 'densenet'\n",
    "nome_modelo = 'resnet'\n",
    "#nome_modelo = 'inception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos treinar o modelo e sempre atualizar os pesos\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o modelo\n",
    "model_ft, input_size = inicializa_modelo(nome_modelo, num_classes, feature_extract, use_pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloca o modelo no device\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações das imagens de treino\n",
    "transform_treino = transforms.Compose([transforms.Resize((input_size,input_size)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                       transforms.ColorJitter(brightness = 0.1, contrast = 0.1, hue = 0.1),\n",
    "                                       transforms.ToTensor(), transforms.Normalize(normMean, normStd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações das imagens de validação\n",
    "transform_val = transforms.Compose([transforms.Resize((input_size,input_size)), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(normMean, normStd)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organiza e transforma os dados de treino\n",
    "set_treino = OrganizaDados(df_treino, transform = transform_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de treino\n",
    "loader_treino = DataLoader(set_treino, batch_size = 32, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O mesmo em validação\n",
    "set_val = OrganizaDados(df_validacao, transform = transform_val)\n",
    "loader_val = DataLoader(set_val, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O mesmo em teste\n",
    "set_teste = OrganizaDados(df_teste, transform = transform_val)\n",
    "loader_teste = DataLoader(set_teste, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos o otimizador Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos cross entropy loss como função de perda\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "epoch_num = 3\n",
    "best_val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    \n",
    "    # Execute a função de treino\n",
    "    loss_train, acc_train = treina_modelo(loader_treino, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Executa a função de validação\n",
    "    loss_val, acc_val = valida_modelo(loader_val, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Calcula as métricas\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    \n",
    "    # Verifica a acurácia em validação\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('Melhor Resultado: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')\n",
    "\n",
    "        torch.save(model.state_dict(), f'resnet_model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot da confusion_matrix\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix',\n",
    "                          cmap = plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Label Real')\n",
    "    plt.xlabel('Label Previsto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo com dados de teste\n",
    "model.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(loader_teste):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim = True)[1]\n",
    "        y_label.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_label, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da confusion matrix\n",
    "plot_labels = labels['chord'].unique().tolist()\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
