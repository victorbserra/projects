{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"9PnR46gb7IMq","executionInfo":{"status":"ok","timestamp":1701128080541,"user_tz":180,"elapsed":7156,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}}},"outputs":[],"source":["import os\n","import cv2\n","import itertools\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from glob import glob\n","from PIL import Image\n","import warnings\n","from google.colab import files\n","from google.cloud import storage\n","warnings.filterwarnings('ignore')\n","\n","# Pytorch\n","import torch\n","from torch import nn, optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models, transforms\n","\n","# Scikit-learn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","# Pacotes para o relatório de hardware\n","import gc\n","import types\n","import pkg_resources\n","# import pytorch_lightning as pl\n","\n","# Seed para reproduzir os mesmos resultados\n","np.random.seed(10)\n","torch.manual_seed(10)\n","torch.cuda.manual_seed(10)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1701128081046,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"GOKpQWpszUkF","outputId":"c0bf8e7d-593b-4fbf-a6cd-ac7f0a13ffd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------Visão Geral do Ambiente---------------------------------------\n","\n","Device: cuda\n","Pasta de Dados:  dados\n","Versões dos Pacotes Requeridos:  [('Pillow', '9.4.0'), ('google', '2.0.3'), ('matplotlib', '3.7.1'), ('numpy', '1.23.5'), ('pandas', '1.5.3'), ('torch', '2.1.0+cu118'), ('torchvision', '0.16.0+cu118'), ('tqdm', '4.66.1')]\n","Dispositivo Que Será Usado Para Treinar o Modelo:  cuda\n","CUDA Está Disponível?  True\n","Versão do PyTorch:  2.1.0+cu118\n","\n","------------------Se NVIDIA-SMI não for encontrado, então CUDA não está disponível------------------\n","\n","Mon Nov 27 23:36:25 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    22W / 300W |      2MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","\n","Limpando a Memória da GPU (se disponível):  None\n","\n","Modelo da GPU:\n","Tesla V100-SXM2-16GB\n","\n","------------------------------------------Fim da Checagem-------------------------------------------\n"]}],"source":["processing_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Verificando se GPU pode ser usada (isso depende da plataforma CUDA estar instalada)\n","torch_aval = torch.cuda.is_available()\n","\n","# Labels para o relatório de verificação\n","lable_1 = 'Visão Geral do Ambiente'\n","lable_2 = 'Se NVIDIA-SMI não for encontrado, então CUDA não está disponível'\n","lable_3 = 'Fim da Checagem'\n","\n","# Função para verificar o que está importado nesta sessão\n","def get_imports():\n","\n","    for name, val in globals().items():\n","        if isinstance(val, types.ModuleType):\n","            name = val.__name__.split(\".\")[0]\n","\n","        elif isinstance(val, type):\n","            name = val.__module__.split(\".\")[0]\n","\n","        poorly_named_packages = {\"PIL\": \"Pillow\", \"sklearn\": \"scikit-learn\"}\n","\n","        if name in poorly_named_packages.keys():\n","            name = poorly_named_packages[name]\n","\n","        yield name\n","\n","# Imports nesta sessão\n","imports = list(set(get_imports()))\n","\n","# Loop para verificar os requerimentos\n","requirements = []\n","for m in pkg_resources.working_set:\n","    if m.project_name in imports and m.project_name!=\"pip\":\n","        requirements.append((m.project_name, m.version))\n","\n","# Pasta com os dados (quando necessário)\n","pasta_dados = r'dados'\n","\n","print(f'{lable_1:-^100}')\n","print()\n","print(f\"Device:\", processing_device)\n","print(f\"Pasta de Dados: \", pasta_dados)\n","print(f\"Versões dos Pacotes Requeridos: \", requirements)\n","print(f\"Dispositivo Que Será Usado Para Treinar o Modelo: \", processing_device)\n","print(f\"CUDA Está Disponível? \", torch_aval)\n","print(\"Versão do PyTorch: \", torch.__version__)\n","print()\n","print(f'{lable_2:-^100}\\n')\n","!nvidia-smi\n","gc.collect()\n","print()\n","print(f\"Limpando a Memória da GPU (se disponível): \", torch.cuda.empty_cache())\n","print(\"\\nModelo da GPU:\")\n","# Modelo da GPU usada\n","!nvidia-smi --query-gpu=name --format=csv,noheader\n","print(f'\\n{lable_3:-^100}')"]},{"cell_type":"markdown","metadata":{"id":"bIvcN9vP0vjC"},"source":["# Import dos Dados"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1988,"status":"ok","timestamp":1701118234423,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"EtkPIFh302U0","outputId":"b09c7f3b-1ce1-41ae-a8e5-826a3bee8ba2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","unrar is already the newest version (1:6.1.5-1).\n","0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n"]}],"source":["!apt-get install unrar"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Prp14T9dIqOo","executionInfo":{"status":"ok","timestamp":1701128098524,"user_tz":180,"elapsed":417,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}}},"outputs":[],"source":["firts_time = True"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"bHjAmUSWIqOo","executionInfo":{"status":"ok","timestamp":1701128104589,"user_tz":180,"elapsed":5707,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}},"outputId":"4194b53a-9f7c-4f76-dddb-28a8b275294c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-824a34b5-f234-4a35-9123-aa0eacc308c3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-824a34b5-f234-4a35-9123-aa0eacc308c3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving projetos-aleatorios-379913-61df4a1c249e.json to projetos-aleatorios-379913-61df4a1c249e.json\n","User uploaded file \"projetos-aleatorios-379913-61df4a1c249e.json\" with length 2372 bytes\n"]}],"source":["if firts_time:\n","    uploaded = files.upload()\n","\n","    for fn in uploaded.keys():\n","        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","            name=fn, length=len(uploaded[fn])))\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"01IYfTFAIqOp","executionInfo":{"status":"ok","timestamp":1701128104589,"user_tz":180,"elapsed":2,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}}},"outputs":[],"source":["os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = f'/content/projetos-aleatorios-379913-61df4a1c249e.json'"]},{"cell_type":"code","source":["storage_client = storage.Client()"],"metadata":{"id":"KWd3z2HKPRFD","executionInfo":{"status":"ok","timestamp":1701128106582,"user_tz":180,"elapsed":2,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZmUGnO58jlLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bucket_name = 'projeto_musical'\n","rar_file_name = 'audio_data.zip'\n","local_rar_path = '/content/' + rar_file_name\n","\n","# Define o bucket e o blob\n","bucket = storage_client.get_bucket(bucket_name)\n","blob = bucket.blob(rar_file_name)\n","\n","#Baixa o arquivo RAR para o ambiente local do Colab\n","blob.download_to_filename(local_rar_path)"],"metadata":{"id":"plpX2unAmMNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile"],"metadata":{"id":"joZCGGwuWCUd","executionInfo":{"status":"ok","timestamp":1701120081809,"user_tz":180,"elapsed":398,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["with zipfile.ZipFile('audio_data.zip', 'r') as zip_ref:\n","    # Extraindo todos os arquivos\n","    zip_ref.extractall('/content')"],"metadata":{"id":"BUg5XgXjmNEo","executionInfo":{"status":"ok","timestamp":1701120393642,"user_tz":180,"elapsed":310728,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cPr1N_jo0pwh"},"source":["# Modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcQl5_Wz1DhX"},"outputs":[],"source":["image_folder = 'unpacked/imagens_audio/melspectrogram_224/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I01qs2ENBU5D"},"outputs":[],"source":["def list_files_in_directory(directory_path):\n","    try:\n","        files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n","        return files\n","    except Exception as e:\n","        return f\"An error occurred: {e}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ppb7q-sqBX0V"},"outputs":[],"source":["parsed_files = list_files_in_directory('unpacked/imagens_audio/melspectrogram_224/')\n","parsed_files_base = [os.path.splitext(f)[0] for f in parsed_files]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5MjZN8024dFu"},"outputs":[],"source":["def resize_and_save_images(input_folder, output_folder, new_size=(224, 224)):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder, exist_ok=True)\n","\n","    # Ajuste aqui para verificar os arquivos corretamente\n","    parsed_files = list_files_in_directory(output_folder)\n","    parsed_files_base = [os.path.splitext(f)[0] for f in parsed_files]\n","\n","    image_paths = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg')) and os.path.splitext(f)[0] not in parsed_files_base]\n","\n","    for path in tqdm(image_paths):\n","        try:\n","            img = cv2.imread(path)\n","            img_resized = cv2.resize(img, new_size)\n","            base_name = os.path.basename(path)\n","            save_path = os.path.join(output_folder, base_name)\n","            cv2.imwrite(save_path, img_resized)\n","        except Exception as e:\n","            print(f\"An error occurred while processing {path}: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7PS8Rlr4hEC","executionInfo":{"status":"ok","timestamp":1699382028308,"user_tz":180,"elapsed":17047,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}},"outputId":"8665d091-998b-4d0d-a232-ba860e9d537f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 1201.81it/s]"]},{"output_type":"stream","name":"stdout","text":["An error occurred while processing unpacked/imagens_audio/melspectrogram/t_DsGsCsFsAsDs_pianopianoDmaj7fastdfsacs.png: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["resize_and_save_images('unpacked/imagens_audio/melspectrogram/', 'unpacked/imagens_audio/melspectrogram_224/', new_size=(224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjZUwJ5u7IMw"},"outputs":[],"source":["labels = pd.read_csv('labels.csv')\n","labels['file_name'] = labels['file_name'].apply(lambda x: f\"{x.split('.')[0]}.png\")\n","labels['file_path'] = labels['file_name'].apply(lambda x: os.path.join(image_folder, x))\n","labels['chord_idx'] = pd.Categorical(labels['chord']).codes\n","def filter_rows(row):\n","    clean_prefix = row['clean'].split('_')[0] if '_' in row['clean'] else row['clean']\n","    chord_prefix = row['chord'].split('\\\\')[0]\n","    return clean_prefix == chord_prefix or chord_prefix in row['clean']\n","\n","# Aplicar o filtro\n","labels = labels[labels.apply(filter_rows, axis=1)].reset_index()"]},{"cell_type":"code","source":["def calcula_img_mean_std(image_paths):\n","\n","    # Define altura e largura que usaremos nas imagens\n","    img_h, img_w = 224, 224\n","\n","    # Listas de controle\n","    imgs = []\n","    means, stdevs = [], []\n","\n","    # Loop de leitura e resize das imagens\n","    for i in tqdm(range(len(image_paths))):\n","        img = cv2.imread(image_paths[i])\n","        img = cv2.resize(img, (img_h, img_w))\n","        imgs.append(img)\n","\n","    # Stack de imagens\n","    imgs = np.stack(imgs, axis=3)\n","    print(imgs.shape)\n","\n","    # Normalização\n","    imgs = imgs.astype(np.float32) / 255.\n","\n","    # Loop de cálculo da média e desvio\n","    for i in range(3):\n","        pixels = imgs[:, :, i, :].ravel()\n","        means.append(np.mean(pixels))\n","        stdevs.append(np.std(pixels))\n","\n","    # BGR --> RGB\n","    means.reverse()\n","    stdevs.reverse()\n","\n","    print(\"normMean = {}\".format(means))\n","    print(\"normStd = {}\".format(stdevs))\n","\n","    return means, stdevs"],"metadata":{"id":"KJnz0OIrNvBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HoCtmHJU7IMx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699382074898,"user_tz":180,"elapsed":46139,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}},"outputId":"30d08159-64ef-4dbb-ebcb-aeb4fc8ae21a"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 17694/17694 [00:19<00:00, 887.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(224, 224, 3, 17694)\n","normMean = [0.3062878, 0.11703696, 0.24005793]\n","normStd = [0.35711697, 0.1699538, 0.21744001]\n"]}],"source":["normMean, normStd = calcula_img_mean_std(labels['file_path'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXLQ02f87IMy"},"outputs":[],"source":["# normMean = [0.30298967, 0.11516446, 0.23933927]\n","# normStd = [0.35485684, 0.16791199, 0.2177703 ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dO2PkeWT7IMy"},"outputs":[],"source":["y = labels['chord_idx']\n","_, df_validacao = train_test_split(labels, test_size = 0.2, random_state = 101, stratify = y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699382074899,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"xTKx6ME07IMz","outputId":"ef4ded82-ad67-4711-e0c3-82ed796117cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3539, 8)"]},"metadata":{},"execution_count":19}],"source":["df_validacao.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1699382074899,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"Kh91_Zp27IM1","outputId":"a0de0b82-a456-4427-9a9e-9a157c7b4574"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["234    28\n","78     28\n","149    27\n","204    27\n","72     27\n","       ..\n","286     7\n","31      7\n","197     6\n","227     6\n","120     6\n","Name: chord_idx, Length: 204, dtype: int64"]},"metadata":{},"execution_count":20}],"source":["df_validacao['chord_idx'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kkNMJZay7IM1"},"outputs":[],"source":["# Esta função identifica se uma imagem faz parte do conjunto train ou val\n","def get_val_rows(x):\n","    val_list = list(df_validacao['clean'])\n","    if str(x) in val_list:\n","        return 'val'\n","    else:\n","        return 'train'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6FXt2sg7IM2"},"outputs":[],"source":["# Identifica treino ou validação\n","labels['train_or_val'] = labels['clean']\n","labels['train_or_val'] = labels['train_or_val'].apply(get_val_rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umfL0m2L7IM3"},"outputs":[],"source":["# Filtra as linhas de treino\n","df_treino = labels[labels['train_or_val'] == 'train']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1699382079875,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"1V3PFD1j7IM3","outputId":"b99f4f3c-ca46-4f0e-c329-6317174fc8f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["13687\n","3539\n"]}],"source":["print(len(df_treino))\n","print(len(df_validacao))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1699382079875,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"FPyUCzyb7IM3","outputId":"1b109733-83c4-4e06-d95a-1112992e9bec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["234    106\n","78     105\n","139    101\n","157    101\n","149    101\n","      ... \n","209     26\n","61      25\n","227     25\n","120     25\n","197     22\n","Name: chord_idx, Length: 204, dtype: int64"]},"metadata":{},"execution_count":25}],"source":["df_treino['chord_idx'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1699382079875,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"Au7nnT2w7IM4","outputId":"d28ee3a1-404f-4c46-cfe4-92f664c45815"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["234    28\n","78     28\n","149    27\n","204    27\n","72     27\n","       ..\n","286     7\n","31      7\n","197     6\n","227     6\n","120     6\n","Name: chord_idx, Length: 204, dtype: int64"]},"metadata":{},"execution_count":26}],"source":["df_validacao['chord_idx'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48wSN6E27IM4"},"outputs":[],"source":["class_counts = df_treino['chord_idx'].value_counts()\n","max_instances = class_counts.max()\n","data_aug_rate = max_instances // class_counts - 1\n","data_aug_rate = data_aug_rate.apply(lambda x: max(x, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTUJEuUf7IM4"},"outputs":[],"source":["augmented_data = []\n","\n","for i in range(204):\n","\n","    if data_aug_rate.to_list()[i] > 0:\n","        class_subset = df_treino[df_treino['chord_idx'] == i]\n","        augmented_subset = pd.DataFrame(np.repeat(class_subset.values, data_aug_rate.to_list()[i], axis=0))\n","        augmented_subset.columns = class_subset.columns\n","        augmented_data.append(augmented_subset)\n","\n","df_treino = pd.concat([df_treino] + augmented_data, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1699382357770,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"dEGikzqK7IM5","outputId":"d82c4ad4-13e0-466c-c94f-c9e765fa3750"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["202    280\n","203    244\n","200    244\n","196    243\n","198    171\n","      ... \n","286     27\n","209     26\n","61      25\n","227     25\n","120     25\n","Name: chord_idx, Length: 204, dtype: int64"]},"metadata":{},"execution_count":39}],"source":["df_treino['chord_idx'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsRqBjoz7IM5"},"outputs":[],"source":["# Podemos dividir o conjunto de validação em um conjunto de validação e um conjunto de teste\n","df_validacao, df_teste = train_test_split(df_validacao, test_size = 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuCnZl9c7IM5"},"outputs":[],"source":["# Reset do índice\n","df_validacao = df_validacao.reset_index()\n","df_teste = df_teste.reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1699382372555,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"UBmEVMHT7IM5","outputId":"fb164a26-2dc6-41dd-b8f7-4e528d80d0a1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1769, 9)"]},"metadata":{},"execution_count":42}],"source":["df_validacao.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1699382373817,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"mi7712Q67IM6","outputId":"46cb5a5a-5481-4f8e-cbf5-165c7d791518"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1770, 9)"]},"metadata":{},"execution_count":43}],"source":["df_teste.shape"]},{"cell_type":"markdown","metadata":{"id":"4B0pEGGQ7IM6"},"source":["### Funções do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1O7ZMfyq7IM8"},"outputs":[],"source":["# feature_extracting é um booleano que define se estamos fazendo um ajuste fino ou extração de recursos.\n","# Se feature_extracting = False, o modelo é ajustado e todos os parâmetros do modelo são atualizados.\n","# Se feature_extracting = True, apenas os parâmetros da última camada são atualizados, os outros permanecem fixos.\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDyAVoNk7IM9"},"outputs":[],"source":["# Função para inicializar diferentes arquiteturas de Deep Learning\n","def inicializa_modelo(model_name, num_classes, feature_extract, use_pretrained = True):\n","\n","    model_ft = None\n","    input_size = 0\n","\n","    # Usaremos o modelo resnet50\n","    if model_name == \"resnet\":\n","\n","        # Tamanho (pixels) das imagens de entrada\n","        input_size = 224\n","\n","        # Carregamos o modelo pré-treinado com todos os pesos\n","        model_ft = models.resnet50(pretrained = use_pretrained)\n","\n","        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","\n","        # Define o número de atributos de entrada\n","        num_ftrs = model_ft.fc.in_features\n","\n","        # Camada linear final para prever a probabilidade das 7 classes com as quais estamos trabalhando\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","\n","    # Usaremos o modelo Densenet121\n","    elif model_name == \"densenet\":\n","\n","        # Tamanho (pixels) das imagens de entrada\n","        input_size = 224\n","\n","        # Carregamos o modelo pré-treinado com todos os pesos\n","        model_ft = models.densenet121(pretrained = use_pretrained)\n","\n","        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","\n","        # Define o número de atributos de entrada\n","        num_ftrs = model_ft.classifier.in_features\n","\n","        # Camada linear final para prever a probabilidade das 7 classes com as quais estamos trabalhando\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","\n","    # Usaremos o Inception V3\n","    elif model_name == \"inception\":\n","\n","        # Tamanho (pixels) das imagens de entrada\n","        # Tenha cuidado, pois espera-se (299 x 299) para o tamanho das imagens e ainda tem saída auxiliar\n","        input_size = 299\n","\n","        # Carregamos o modelo pré-treinado com todos os pesos\n","        model_ft = models.inception_v3(pretrained = use_pretrained)\n","\n","        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","\n","        # Tratando a auxilary net da arquitetura Inceptio\n","        model_ft.aux_logits = False\n","\n","        # Tratando a primary net\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","\n","    else:\n","        print(\"Modelo inválido...\")\n","        exit()\n","\n","    return model_ft, input_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKdRQIzF7IM9"},"outputs":[],"source":["# Defina um organizador de dados para modelo PyTorch\n","class OrganizaDados(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        X = Image.open(self.df['file_path'][index]).convert('RGB')\n","        y = torch.tensor(int(self.df['chord_idx'][index]))\n","\n","        if self.transform:\n","          X = np.array(X)\n","          X = np.ascontiguousarray(X)\n","          X = Image.fromarray(X)\n","          X = self.transform(X)\n","\n","        return X, y"]},{"cell_type":"code","source":["# del loader_treino\n","# torch.cuda.empty_cache()"],"metadata":{"id":"bm5XmEaCMUKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i32mk1nZ7IM-"},"outputs":[],"source":["# Função para calcular erro em treino e validação durante o treinamento\n","class CalculaMetricas(object):\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNrSR8zr7IM_"},"outputs":[],"source":["total_loss_train, total_acc_train = [],[]\n","# Função de treino do modelo\n","def treina_modelo(treino_loader, model, criterion, optimizer, epoch):\n","\n","    # Coloca o modelo em modo de treino\n","    model.train()\n","\n","    # Inicializa objetos de cálculo de métricas\n","    train_loss = CalculaMetricas()\n","    train_acc = CalculaMetricas()\n","\n","    # Iteração\n","    curr_iter = (epoch - 1) * len(treino_loader)\n","\n","    # Loop de treino\n","    for i, data in enumerate(treino_loader):\n","\n","        # Extra os dados\n","        images, labels = data\n","\n","        # Tamanho da imagem\n","        N = images.size(0)\n","\n","        # Coloca imagens e labels no device\n","        images = Variable(images).to(device)\n","        labels = Variable(labels).to(device)\n","\n","        # Zera os gradientes\n","        optimizer.zero_grad()\n","\n","        # Previsão do modelo\n","        outputs = model(images)\n","\n","        # Erro do modelo\n","        loss = criterion(outputs, labels)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Obtem a previsão de maior probabilidade\n","        prediction = outputs.max(1, keepdim = True)[1]\n","\n","        # Atualiza as métricas\n","        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n","        train_loss.update(loss.item())\n","\n","        # Iteração\n","        curr_iter += 1\n","\n","        # Print e update das métricas\n","        # A condição *** and curr_iter < 1000 *** pode ser removida se você quiser treinar com o dataset completo\n","        if (i + 1) % 100 == 0 and curr_iter < 1000:\n","            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (epoch,\n","                                                                                       i + 1,\n","                                                                                       len(treino_loader),\n","                                                                                       train_loss.avg,\n","                                                                                       train_acc.avg))\n","            total_loss_train.append(train_loss.avg)\n","            total_acc_train.append(train_acc.avg)\n","\n","    return train_loss.avg, train_acc.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-35GIW_f7INA"},"outputs":[],"source":["total_loss_val, total_acc_val = [],[]\n","# Função para validação\n","def valida_modelo(val_loader, model, criterion, optimizer, epoch):\n","\n","    # Coloca o modelo em modo de validação\n","    model.eval()\n","\n","    # Inicializa objetos de cálculo de métricas\n","    val_loss = CalculaMetricas()\n","    val_acc = CalculaMetricas()\n","\n","    # Validação\n","    with torch.no_grad():\n","        for i, data in enumerate(val_loader):\n","\n","            images, labels = data\n","\n","            N = images.size(0)\n","\n","            images = Variable(images).to(device)\n","\n","            labels = Variable(labels).to(device)\n","\n","            outputs = model(images)\n","\n","            prediction = outputs.max(1, keepdim = True)[1]\n","\n","            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n","\n","            val_loss.update(criterion(outputs, labels).item())\n","\n","    print('------------------------------------------------------------')\n","    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n","    print('------------------------------------------------------------')\n","\n","    return val_loss.avg, val_acc.avg"]},{"cell_type":"markdown","metadata":{"id":"jzzzUYEsFb16"},"source":["## Inicializando o Modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uc6skneF7INB"},"outputs":[],"source":["# Modelo que será treinado\n","#nome_modelo = 'densenet'\n","nome_modelo = 'resnet'\n","#nome_modelo = 'inception'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KvwO2yI7INB"},"outputs":[],"source":["num_classes = 204"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dNBu044Fkcw"},"outputs":[],"source":["# Vamos treinar o modelo e sempre atualizar os pesos\n","feature_extract = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99ltrPrcFknZ"},"outputs":[],"source":["# Inicializa o modelo\n","model_ft, input_size = inicializa_modelo(nome_modelo, num_classes, feature_extract, use_pretrained = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8u41DTSFqK1"},"outputs":[],"source":["device = processing_device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXwz9OA0Fkto"},"outputs":[],"source":["# Coloca o modelo no device\n","model = model_ft.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ytc47U8NFkz2"},"outputs":[],"source":["transform_treino = transforms.Compose([#transforms.Resize((input_size,input_size)),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.RandomVerticalFlip(),\n","                                       transforms.RandomRotation(20),\n","                                       transforms.ColorJitter(brightness = 0.1, contrast = 0.1, hue = 0.1),\n","                                       transforms.ToTensor(), transforms.Normalize(normMean, normStd)\n","                                       ])"]},{"cell_type":"code","source":["normMeanVal, normStdVal = calcula_img_mean_std(df_validacao['file_path'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhc37i9aZWdq","executionInfo":{"status":"ok","timestamp":1699382407334,"user_tz":180,"elapsed":4551,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"}},"outputId":"e8115597-3778-44db-ebcd-8d5a50667733"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1769/1769 [00:01<00:00, 924.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(224, 224, 3, 1769)\n","normMean = [0.30591327, 0.11683494, 0.23995464]\n","normStd = [0.35690492, 0.16974604, 0.21746446]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMkCsI21Fk8H"},"outputs":[],"source":["transform_val = transforms.Compose([#transforms.Resize((input_size,input_size)),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize(normMeanVal, normStdVal)])"]},{"cell_type":"markdown","metadata":{"id":"76K9L-OjGMIn"},"source":["## Carregando Dataloader"]},{"cell_type":"code","source":["del loader_treino\n","del loader_val\n","del loader_teste\n","del model_ft\n","torch.cuda.empty_cache()"],"metadata":{"id":"Rsu4ZXLiNGHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-XWha0EFk_B"},"outputs":[],"source":["set_treino = OrganizaDados(df_treino, transform = transform_treino)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_DkchgeGPzh"},"outputs":[],"source":["loader_treino = DataLoader(set_treino, batch_size = 32, shuffle = True, num_workers = 4, persistent_workers=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tLyGA4pGP_Y"},"outputs":[],"source":["set_val = OrganizaDados(df_validacao, transform = transform_val)\n","loader_val = DataLoader(set_val, batch_size = 32, shuffle = False, num_workers = 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NpMyGsOGQDU"},"outputs":[],"source":["set_teste = OrganizaDados(df_teste, transform = transform_val)\n","loader_teste = DataLoader(set_teste, batch_size = 32, shuffle = False, num_workers = 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xofD-3OIGQGi"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr = 1e-3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYr9rQhpGQKa"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"markdown","metadata":{"id":"CKpsdvA8GdWI"},"source":["## Treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BqC39guoGQNt"},"outputs":[],"source":["# Hiperparâmetros\n","epoch_num = 10\n","best_val_acc = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":2726,"status":"ok","timestamp":1699382426686,"user":{"displayName":"Victor Augusto","userId":"02582484546541171974"},"user_tz":180},"id":"9g1UrvC3GfJJ","outputId":"dcf83b0f-8edf-46fe-bb0c-dc20d455015a"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<ipython-input-48-dcf8aa840845>\u001b[0m in \u001b[0;36mtreina_modelo\u001b[0;34m(treino_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"]}],"source":["%%time\n","for epoch in range(1, epoch_num + 1):\n","\n","    # Execute a função de treino\n","    loss_train, acc_train = treina_modelo(loader_treino, model, criterion, optimizer, epoch)\n","\n","    # Executa a função de validação\n","    loss_val, acc_val = valida_modelo(loader_val, model, criterion, optimizer, epoch)\n","\n","    # Calcula as métricas\n","    total_loss_val.append(loss_val)\n","    total_acc_val.append(acc_val)\n","\n","    # Verifica a acurácia em validação\n","    if acc_val > best_val_acc:\n","        best_val_acc = acc_val\n","        print('*****************************************************')\n","        print('Melhor Resultado: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n","        print('*****************************************************')\n","\n","        torch.save(model.state_dict(), f'{nome_modelo}_model_{epoch}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDe7FJ9zw2O7"},"outputs":[],"source":["# Plot\n","fig = plt.figure(num = 2)\n","fig1 = fig.add_subplot(2,1,1)\n","fig2 = fig.add_subplot(2,1,2)\n","fig1.plot(total_loss_train, label = 'Erro em Treino')\n","fig1.plot(total_acc_train, label = 'Acurácia em Treino')\n","fig2.plot(total_loss_val, label = 'Erro em Validação')\n","fig2.plot(total_acc_val, label = 'Acurácia em Validação')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RxaXDJtGfNc"},"outputs":[],"source":["# Função de plot da confusion_matrix\n","def plot_confusion_matrix(cm,\n","                          classes,\n","                          normalize = False,\n","                          title = 'Confusion matrix',\n","                          cmap = plt.cm.Blues):\n","\n","    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment = \"center\",\n","                 color = \"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Label Real')\n","    plt.xlabel('Label Previsto')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGYNNOGRGfRR"},"outputs":[],"source":["# Avaliação do modelo com dados de teste\n","model.eval()\n","y_label = []\n","y_predict = []\n","with torch.no_grad():\n","    for i, data in enumerate(loader_teste):\n","        images, labels_2 = data\n","        N = images.size(0)\n","        images = Variable(images).to(device)\n","        outputs = model(images)\n","        prediction = outputs.max(1, keepdim = True)[1]\n","        y_label.extend(labels_2.cpu().numpy())\n","        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6Hd-IvYGfUz"},"outputs":[],"source":["# Cria a confusion matrix\n","confusion_mtx = confusion_matrix(y_label, y_predict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8XZePtkiGfaY"},"outputs":[],"source":["# Plot da confusion matrix\n","plot_labels = labels['chord'].unique().tolist()\n","# plot_confusion_matrix(confusion_mtx, plot_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBaAF84IxzWF"},"outputs":[],"source":["# Gera o relatório de classificação\n","report = classification_report(y_label, y_predict, target_names = plot_labels)\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjlzYfSox22Q"},"outputs":[],"source":["# Plot de erros por classe\n","label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis = 1)\n","plt.bar(np.arange(373),label_frac_error)\n","plt.xlabel('Label Real')\n","plt.ylabel('Classificação Incorreta')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4fKn7JxGQQ0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONSeRYs6FlDI"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}